{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "rating = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "user = pd.read_csv('data/BX-Users.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "book = pd.read_csv('data/BX-Books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "book_rating = pd.merge(rating, book, on='ISBN')\n",
    "cols = ['Year-Of-Publication', 'Publisher', 'Book-Author', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n",
    "book_rating.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "rating_count = (book_rating.\n",
    "     groupby(by = ['Book-Title'])['Book-Rating'].\n",
    "     count().\n",
    "     reset_index().\n",
    "     rename(columns = {'Book-Rating': 'RatingCount_book'})\n",
    "     [['Book-Title', 'RatingCount_book']]\n",
    "    )\n",
    "    \n",
    "threshold = 25\n",
    "rating_count = rating_count.query('RatingCount_book >= @threshold')\n",
    "\n",
    "user_rating = pd.merge(rating_count, book_rating, left_on='Book-Title', right_on='Book-Title', how='left')\n",
    "\n",
    "user_count = (user_rating.\n",
    "     groupby(by = ['User-ID'])['Book-Rating'].\n",
    "     count().\n",
    "     reset_index().\n",
    "     rename(columns = {'Book-Rating': 'RatingCount_user'})\n",
    "     [['User-ID', 'RatingCount_user']]\n",
    "    )\n",
    "    \n",
    "threshold = 20\n",
    "user_count = user_count.query('RatingCount_user >= @threshold')\n",
    "\n",
    "combined = user_rating.merge(user_count, left_on = 'User-ID', right_on = 'User-ID', how = 'inner')\n",
    "\n",
    "print('Number of unique books: ', combined['Book-Title'].nunique())\n",
    "print('Number of unique users: ', combined['User-ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conduct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "y_pred = decoder_op\n",
    "y_true = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "pred_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    epochs = 100\n",
    "    batch_size = 35\n",
    "\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(user_book_matrix.shape[0] / batch_size)\n",
    "    user_book_matrix = np.array_split(user_book_matrix, num_batches)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "        for batch in user_book_matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "    user_book_matrix = np.concatenate(user_book_matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: user_book_matrix})\n",
    "\n",
    "    pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "\n",
    "    pred_data = pred_data.stack().reset_index(name='Book-Rating')\n",
    "    pred_data.columns = ['User-ID', 'Book-Title', 'Book-Rating']\n",
    "    pred_data['User-ID'] = pred_data['User-ID'].map(lambda value: users[value])\n",
    "    pred_data['Book-Title'] = pred_data['Book-Title'].map(lambda value: books[value])\n",
    "    \n",
    "    keys = ['User-ID', 'Book-Title']\n",
    "    index_1 = pred_data.set_index(keys).index\n",
    "    index_2 = combined.set_index(keys).index\n",
    "\n",
    "    top_ten_ranked = pred_data[~index_1.isin(index_2)]\n",
    "    top_ten_ranked = top_ten_ranked.sort_values(['User-ID', 'Book-Rating'], ascending=[True, False])\n",
    "    top_ten_ranked = top_ten_ranked.groupby('User-ID').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_rating.loc[book_rating['User-ID'] == 278582].sort_values(by=['Book-Rating'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
